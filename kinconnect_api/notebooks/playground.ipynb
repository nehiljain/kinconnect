{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinconnect_api.config import MONGO_CONNECTION_STRING, load_dotenv\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import os, pymongo, pprint\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "# Define collection and index name\n",
    "db_name = \"kinconnect\"\n",
    "collection_name = \"app\"\n",
    "atlas_collection = client[db_name][collection_name]\n",
    "vector_search_index = \"vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "\n",
    "uri = MONGO_CONNECTION_STRING\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP\")\n",
    "data = loader.load()\n",
    "# Split PDF into documents\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "markdown_document = \"# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(data)\n",
    "# Print the first document\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_fireworks import FireworksEmbeddings\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Create the vector store\n",
    "vector_search = MongoDBAtlasVectorSearch.from_documents(\n",
    "    documents = docs,\n",
    "    embedding = FireworksEmbeddings(model=\"nomic-ai/nomic-embed-text-v1.5\"),\n",
    "    collection = atlas_collection,\n",
    "    index_name = vector_search_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinconnect_api.config import load_dotenv\n",
    "load_dotenv()\n",
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_fireworks import ChatFireworks\n",
    "\n",
    "portfolio_prompt_string = open(\"/Users/nehiljain/code/kinconnect/kinconnect_api/prompts/prompt_extract_portfolio.txt\", \"r\").read()\n",
    "profile_prompt_string = open(\"/Users/nehiljain/code/kinconnect/kinconnect_api/prompts/prompt_extract_proile_attributes.txt\", \"r\").read()\n",
    "career_history_prompt_string = open(\"/Users/nehiljain/code/kinconnect/kinconnect_api/prompts/prompt_extract_career_firefunc.txt\", \"r\").read()\n",
    "\n",
    "firefunc_model = \"accounts/fireworks/models/firefunction-v2\"\n",
    "mistral_model = \"accounts/fireworks/models/mistral-7b-instruct-v3\"\n",
    "\n",
    "class ProfileModel(BaseModel):\n",
    "    name: str = Field(..., title=\"Name of the person\")\n",
    "    honors: list[str] = Field(None, title=\"Honors, Awards and recognition they have received in life\")\n",
    "    interests: list[str] = Field(..., title=\"Interests and current focus of theirs the work or the event\")\n",
    "    skills: list[str] = Field(..., title=\"Skills they have\")\n",
    "\n",
    "\n",
    "class CareerEntry(BaseModel):\n",
    "    company: str = Field(..., description=\"Company they worked at\")\n",
    "    title: str = Field(..., description=\"Title of the role they held\")\n",
    "    description: str = Field(..., description=\"Description of the role they held\")\n",
    "    start_date: str = Field(..., description=\"Start date of the role\")\n",
    "    end_date: str = Field(..., description=\"End date of the role\")\n",
    "\n",
    "class CareerHistory(BaseModel):\n",
    "    history: List[CareerEntry] = Field(..., description=\"All the companies you have been at as part of your career\")\n",
    "\n",
    "\n",
    "class ProjectEntry(BaseModel):\n",
    "    title: str = Field(..., title=\"Title of the project\")\n",
    "    description: str = Field(..., title=\"Description of the project\")\n",
    "\n",
    "class Portfolio(BaseModel):\n",
    "    projects: List[ProjectEntry] = Field(..., description=\"All the projects you have worked on\")\n",
    "\n",
    "def call_api(prompt, structed_class, model):\n",
    "\n",
    "    fireworks_llm = ChatFireworks(model=model)\n",
    "    fireworks_llm = fireworks_llm.with_structured_output(structed_class)\n",
    "    \n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\n",
    "            \"output\": output.dict(),\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": e\n",
    "        }\n",
    "\n",
    "\n",
    "# print(call_api(\"I am a google engineer with 2 years of experience\", Portfolio, mistral_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_pair = {\"Timestamp\":\"01/07/2024 10:51:13\",\"What is your name? \":\"Alex Chi\",\"What are your interests? (ie technical topic, coding language, business problem).\":\"I'm passionate about AI ethics, natural language processing, and creating accessible technology. I'm proficient in Python, TensorFlow, and have experience with large language models.\",\"If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.\":\"I have an idea for an AI-powered language learning assistant. It's in the edtech sector, solving the problem of personalized language acquisition for adult learners. The project would use GPT-based models to create interactive, context-aware conversations tailored to each user's proficiency level and learning style.\",\"What is your strongest functional role (such as developer, UX, business, product)? Please share one or two things about your experience in role your experience, for example a success, companies you worked for, how many years experience, a challenging project, etc.\":\"My strongest role is as an AI researcher and developer. I have 5 years of experience, including 3 years at Google AI, where I contributed to the development of BERT. One of my biggest successes was implementing a bias detection and mitigation system for large language models, which is now used across multiple Google products.\",\"Describe your career history? Think of it like a snapshot of your LinkedIn that is relevant for your teammates at this hackathon.\":\"- AI Research Scientist at OpenAI (Current, 2 years)\\n- Senior AI Developer at Google AI (3 years)\\n- Machine Learning Engineer at Coursera (2 years)\\n- Ph.D. in Computer Science, specializing in NLP, from Stanford University\",\"What are some of the projects you are proud of? Share links and description of what you did and why you are so proud of them\":\"Project 1: Bias Mitigation in LLMs\\nDescription: Developed a system to detect and mitigate biases in large language models. This project involved creating a comprehensive framework for identifying various types of biases (gender, racial, socioeconomic) and implementing techniques to reduce these biases during model training and inference.\\nLink: github.com/alexchi/bias-mitigation-llm\\n\\nProject 2: Multilingual NLP Toolkit\\nDescription: Created an open-source toolkit for multilingual natural language processing tasks. This project supports over 100 languages and includes modules for tokenization, named entity recognition, sentiment analysis, and machine translation.\\nLink: github.com/alexchi/multilingual-nlp-toolkit\\n\\nProject 3: AI-Powered Code Explanation Tool\\nDescription: Developed a tool that uses GPT-3 to generate human-readable explanations of complex code snippets. This project aims to make programming more accessible to beginners and non-technical stakeholders.\\nLink: github.com/alexchi/code-explainer-ai\\n\",\"Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?\":\"I'm particularly interested in meeting UX designers and product managers who have experience in educational technology. I'd also love to connect with frontend developers who can create intuitive, accessible interfaces for AI-powered applications.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_question_answer_pair_to_markdown(question_answer_pair):\n",
    "    markdown = \"\"\n",
    "    for question, answer in question_answer_pair.items():\n",
    "        markdown += f\"## {question}\\n{answer}\\n\\n\"\n",
    "    return markdown\n",
    "\n",
    "def extract_career_history(question_answer_pair_markdown):\n",
    "    career_history_prompt = career_history_prompt_string.replace(\"{{bio}}\", question_answer_pair_markdown)\n",
    "\n",
    "    return call_api(career_history_prompt, CareerHistory, firefunc_model)\n",
    "\n",
    "\n",
    "def extract_profile_details(question_answer_pair_markdown):\n",
    "    profile_prompt = profile_prompt_string.replace(\"{{bio}}\", question_answer_pair_markdown)\n",
    "    return call_api(profile_prompt, ProfileModel, mistral_model)\n",
    "\n",
    "def extract_portfolio(question_answer_pair_markdown):\n",
    "    portfolio_prompt = portfolio_prompt_string.replace(\"{{bio}}\", question_answer_pair_markdown)\n",
    "    return call_api(portfolio_prompt, Portfolio, mistral_model)\n",
    "\n",
    "markdown_profile = convert_question_answer_pair_to_markdown(question_answer_pair)\n",
    "career_history = extract_career_history(markdown_profile)\n",
    "profile_details = extract_profile_details(markdown_profile)\n",
    "portfolio = extract_portfolio(markdown_profile)\n",
    "profile = profile_details['output']\n",
    "profile['career_history'] = career_history['output']\n",
    "profile['portfolio'] = portfolio['output']\n",
    "profile['form_submission'] = markdown_profile\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateEmbeddingResponse(data=[Embedding(embedding=[-0.03369140625, 0.03814697265625, -0.130859375, 0.022735595703125, 0.03460693359375, 0.0712890625, -0.011383056640625, -0.0523681640625, 0.0016880035400390625, -0.002918243408203125, -0.027923583984375, 0.033447265625, 0.04351806640625, 0.0233154296875, -0.039276123046875, -0.115478515625, -0.0016450881958007812, -0.075439453125, 0.022125244140625, -0.0017156600952148438, -0.0771484375, -0.06463623046875, 0.06201171875, -0.03533935546875, 0.00534820556640625, 0.034149169921875, -0.06451416015625, -0.0272674560546875, -0.00991058349609375, 0.03228759765625, 0.0113983154296875, -0.017181396484375, -0.00899505615234375, -0.05438232421875, 0.0121612548828125, -0.047607421875, 0.0171356201171875, 0.041778564453125, 0.026580810546875, 0.0211944580078125, 0.0186767578125, 0.02899169921875, -0.0253448486328125, -0.0198516845703125, 0.08709716796875, -0.02374267578125, 0.04827880859375, 0.025360107421875, 0.0186309814453125, -0.046539306640625, 0.0021209716796875, -0.07476806640625, 0.0228271484375, -0.0259857177734375, 0.07781982421875, 0.040130615234375, 0.033233642578125, -0.001598358154296875, 0.04296875, 0.0191650390625, 0.0511474609375, 0.01983642578125, 0.02655029296875, 0.0004584789276123047, 0.0296630859375, -0.02276611328125, -0.044708251953125, 0.042816162109375, -0.0051422119140625, -0.0029506683349609375, 0.028961181640625, -0.03900146484375, 0.01300048828125, -0.0009608268737792969, -0.025848388671875, 0.031982421875, -0.0267333984375, -0.01340484619140625, -0.028076171875, 0.0281219482421875, 0.054962158203125, -0.021820068359375, 0.0170745849609375, -0.007595062255859375, 0.037628173828125, 0.0078887939453125, -0.00428009033203125, 0.0229949951171875, -0.0104522705078125, 0.09393310546875, 0.01174163818359375, 0.0104522705078125, 0.03759765625, 0.0186004638671875, -0.0938720703125, 0.01515960693359375, -0.0455322265625, 0.0014753341674804688, -0.0152587890625, -0.0498046875, -0.037994384765625, 0.000453948974609375, 0.0501708984375, -0.0248565673828125, 0.0771484375, -0.0002334117889404297, -0.03167724609375, 0.0272979736328125, -0.049072265625, -0.007419586181640625, -0.01390838623046875, 0.0318603515625, -0.040069580078125, -0.022430419921875, -0.0008268356323242188, -0.006534576416015625, 0.068115234375, -0.048553466796875, 0.040771484375, 0.060516357421875, -0.003810882568359375, -0.02392578125, 0.03509521484375, -0.00010293722152709961, 0.01023101806640625, -0.0027828216552734375, -0.068603515625, 0.0296783447265625, 0.00313568115234375, -0.045989990234375, 0.00434112548828125, -0.040985107421875, -0.01611328125, -0.017059326171875, -0.03155517578125, 0.072021484375, -0.0411376953125, -0.054443359375, 0.042449951171875, 0.0028095245361328125, 0.09124755859375, -0.02923583984375, 0.006565093994140625, -0.033172607421875, 0.0239105224609375, -0.01543426513671875, 0.005809783935546875, 0.018280029296875, -0.02935791015625, 0.05902099609375, 0.007793426513671875, 0.051239013671875, -0.00244140625, 0.040069580078125, -0.0333251953125, -0.05511474609375, -0.007694244384765625, -0.00036072731018066406, 0.0228118896484375, -0.03961181640625, 0.054290771484375, -0.02655029296875, -0.0024204254150390625, 0.0182647705078125, -0.000701904296875, -0.06475830078125, 0.0177459716796875, -0.00646209716796875, 0.002384185791015625, 0.021026611328125, -0.036865234375, -0.046356201171875, 0.0019197463989257812, 0.0174560546875, 0.058013916015625, -0.045440673828125, 0.028778076171875, -0.00777435302734375, 0.012908935546875, -0.063720703125, 0.005107879638671875, -0.02069091796875, -0.048187255859375, 0.007415771484375, 0.0083770751953125, -0.05718994140625, 0.05438232421875, -0.00399017333984375, -0.0911865234375, -0.033660888671875, 0.00824737548828125, 0.03125, -0.02203369140625, -0.04522705078125, -0.01995849609375, -0.06024169921875, 0.056396484375, 0.035430908203125, 0.04290771484375, -0.0916748046875, 0.01349639892578125, 0.027008056640625, -0.0380859375, 0.020111083984375, -0.0305328369140625, 0.050811767578125, -0.008148193359375, 0.0156097412109375, 0.0051727294921875, -0.023651123046875, 0.11151123046875, -0.01375579833984375, -0.0213165283203125, 0.03399658203125, -0.061798095703125, -0.0262298583984375, -0.0202178955078125, 0.0045928955078125, -0.0716552734375, 0.02374267578125, 0.006595611572265625, 0.0182647705078125, -0.0255584716796875, 0.0150909423828125, 0.07073974609375, 0.057037353515625, 0.0185089111328125, 0.05352783203125, -0.0179443359375, 0.0472412109375, -0.0438232421875, -0.07122802734375, 0.036529541015625, 0.047515869140625, 0.02239990234375, -0.0098419189453125, 0.01264190673828125, 0.01425933837890625, 0.044525146484375, 0.002227783203125, -0.00445556640625, 0.037841796875, 0.03125, -0.04461669921875, -0.035125732421875, 0.00033283233642578125, -0.02923583984375, -0.0194244384765625, 0.052734375, 0.07183837890625, -0.0306854248046875, -0.03143310546875, -0.0035877227783203125, 0.01161956787109375, 0.04400634765625, -0.021392822265625, 0.01520538330078125, 0.0292816162109375, 0.01389312744140625, -0.031890869140625, 0.00530242919921875, -0.0384521484375, 0.0482177734375, -0.036651611328125, -0.0216522216796875, -0.0181732177734375, -0.019256591796875, 0.01235198974609375, -0.0041961669921875, -0.032745361328125, -0.0494384765625, 0.035552978515625, -0.00902557373046875, 0.00762939453125, -0.018157958984375, 0.005115509033203125, -0.00450897216796875, -0.00804901123046875, -0.023193359375, -0.002788543701171875, 0.020294189453125, -0.024322509765625, -0.05267333984375, -0.005462646484375, 0.01424407958984375, 0.0160675048828125, 0.037322998046875, -0.01264190673828125, 0.00800323486328125, -0.0003654956817626953, -0.03582763671875, -0.005519866943359375, -0.033172607421875, 0.0156707763671875, 0.034820556640625, -0.01151275634765625, 0.1094970703125, 0.01007843017578125, 0.0065765380859375, -0.000728607177734375, -0.0296478271484375, 0.0438232421875, 0.0225982666015625, 0.04534912109375, -0.023162841796875, -0.020843505859375, 0.005645751953125, 0.00988006591796875, 0.047698974609375, -0.047576904296875, -0.053192138671875, 0.04583740234375, -0.00010788440704345703, 0.059051513671875, -0.07965087890625, 0.034759521484375, 0.034393310546875, 0.046295166015625, 0.057403564453125, -0.0057220458984375, -0.0283660888671875, -0.005100250244140625, -0.0200347900390625, -0.037139892578125, 0.007080078125, 0.07427978515625, 0.048736572265625, -0.004627227783203125, -0.0024261474609375, -0.00792694091796875, -0.006587982177734375, 0.0166778564453125, 0.01329803466796875, -0.05560302734375, -0.039031982421875, 0.023590087890625, 0.0158843994140625, 0.01495361328125, -0.020751953125, 0.0263671875, 0.103515625, 0.0244140625, 0.0364990234375, -0.084716796875, -0.029876708984375, 0.0129547119140625, -0.00958251953125, -0.04376220703125, 0.053863525390625, 0.007755279541015625, -0.057464599609375, 0.050689697265625, -0.05010986328125, 0.0226593017578125, -0.0242462158203125, -0.0419921875, 0.00423431396484375, 0.0458984375, -0.0182037353515625, 0.0125579833984375, 0.02392578125, 0.02325439453125, -0.035980224609375, -0.06634521484375, -0.001712799072265625, -0.0207977294921875, 0.0057830810546875, 0.0408935546875, -0.01477813720703125, -0.0228118896484375, -0.003734588623046875, 0.03863525390625, 0.0357666015625, 0.0374755859375, 0.0077362060546875, -0.01537322998046875, -0.06109619140625, 0.01385498046875, -0.063720703125, -0.00010710954666137695, 0.0322265625, -0.02105712890625, -0.00749969482421875, 0.051361083984375, 0.01090240478515625, -0.0274810791015625, 0.04150390625, -0.0121612548828125, -0.01326751708984375, -0.005950927734375, -0.023468017578125, -0.0224609375, -0.045623779296875, 0.0038356781005859375, 0.02020263671875, -0.051513671875, 0.036224365234375, 0.0153045654296875, 0.048126220703125, 0.0147552490234375, -0.039764404296875, -0.026031494140625, 0.001705169677734375, -0.0095062255859375, 0.0125885009765625, 0.045013427734375, -0.0010805130004882812, -0.05682373046875, -0.005615234375, -0.019775390625, -0.01751708984375, 0.056640625, -0.03607177734375, 0.004268646240234375, -0.037994384765625, 0.051544189453125, -0.0222015380859375, 0.045440673828125, -0.07403564453125, 0.00677490234375, 0.0496826171875, 0.0435791015625, -0.021148681640625, 0.02294921875, -0.010345458984375, -0.0196990966796875, 0.047454833984375, 0.055267333984375, -0.049041748046875, -0.0252532958984375, -0.07220458984375, 0.0253448486328125, 0.020416259765625, 0.03619384765625, -0.01523590087890625, 0.00626373291015625, 0.0283660888671875, 0.0035247802734375, 0.0252227783203125, 0.03265380859375, 0.045379638671875, -0.029815673828125, 0.0003643035888671875, -0.0218505859375, 0.01212310791015625, 0.0662841796875, 0.0227813720703125, 0.046234130859375, -0.06158447265625, 0.0384521484375, -0.038787841796875, 0.01284027099609375, 0.035430908203125, -0.035797119140625, 0.0267181396484375, -0.006198883056640625, 0.022247314453125, 0.0238800048828125, -0.0064239501953125, 0.053924560546875, 0.00986480712890625, -0.054107666015625, -0.0262451171875, 0.045135498046875, 0.0235748291015625, -0.0233612060546875, 0.0088043212890625, -0.0098114013671875, -0.0160980224609375, 0.05572509765625, -0.03411865234375, 0.013641357421875, 0.051239013671875, 0.0134124755859375, -0.0019989013671875, -0.04913330078125, -0.02838134765625, -0.0255126953125, 0.01013946533203125, -0.0206451416015625, -0.0460205078125, -0.0177764892578125, -0.04119873046875, -0.040069580078125, -0.009979248046875, -0.021514892578125, 0.027191162109375, 0.0028533935546875, 0.0693359375, -0.02105712890625, 0.0287322998046875, 0.0721435546875, 0.0270538330078125, -0.033905029296875, 0.0146636962890625, -0.0340576171875, 0.0010557174682617188, 0.01406097412109375, 0.0193939208984375, 0.0548095703125, 0.07373046875, 0.01087188720703125, -0.038330078125, -0.0244140625, 0.047943115234375, -0.022613525390625, 0.01522064208984375, -0.06451416015625, -0.06365966796875, 0.045013427734375, -0.048797607421875, -0.0208740234375, -0.0104827880859375, 0.051605224609375, 0.0252227783203125, -0.0360107421875, 0.061279296875, 0.000606536865234375, -0.068115234375, 0.0465087890625, 0.04193115234375, -0.033050537109375, -0.0152587890625, -0.0667724609375, -0.019134521484375, 0.0290679931640625, -0.005016326904296875, 0.005130767822265625, 0.0139312744140625, -0.0156402587890625, 0.046722412109375, -0.0241851806640625, -0.0303497314453125, 0.0009975433349609375, -0.01934814453125, -0.05126953125, -0.03460693359375, 0.056793212890625, 0.019744873046875, 0.0283660888671875, -0.039154052734375, 0.0137481689453125, -0.017547607421875, 0.0282135009765625, 0.0289764404296875, -0.01221466064453125, -0.0184783935546875, 0.02984619140625, 0.0297698974609375, -0.03717041015625, 0.0246734619140625, 0.0054473876953125, -0.04144287109375, -0.0489501953125, 0.061126708984375, 0.007720947265625, 0.01824951171875, 0.056854248046875, -0.0003802776336669922, -0.017364501953125, 0.032623291015625, -0.01558685302734375, -0.0005922317504882812, -0.042022705078125, -0.005100250244140625, 0.0260467529296875, -0.0443115234375, -0.038177490234375, 0.021148681640625, 0.04547119140625, -0.021209716796875, -0.060882568359375, -0.0242156982421875, -0.037200927734375, 0.0008435249328613281, -0.036102294921875, 0.0179595947265625, -0.0173797607421875, -0.04144287109375, -0.0160675048828125, 0.0631103515625, -0.0562744140625, 0.01039886474609375, 0.00820159912109375, -0.0421142578125, 0.006511688232421875, -0.05340576171875, -0.0164337158203125, 0.08502197265625, -0.06439208984375, 0.003498077392578125, 0.0183258056640625, -0.008392333984375, -0.032012939453125, 0.01506805419921875, 0.05670166015625, -0.04693603515625, -0.0411376953125, 0.00797271728515625, -0.01294708251953125, 0.03155517578125, 0.0430908203125, 0.039825439453125, -0.029632568359375, 0.037811279296875, 0.072021484375, 0.0014600753784179688, 0.01410675048828125, -0.01104736328125, -0.0195465087890625, -0.0209503173828125, 0.016387939453125, -0.020111083984375, 0.01351165771484375, 0.02374267578125, -0.00019180774688720703, 0.041839599609375, -0.00014853477478027344, -0.023651123046875, -0.039520263671875, -0.0219879150390625, -0.08154296875, 0.0341796875, -0.0211029052734375, 0.05181884765625, 0.0171356201171875, -0.04827880859375, -0.01537322998046875, 0.0258941650390625, -0.004150390625, -0.022613525390625, 0.04693603515625, -0.0806884765625, -0.038482666015625, -0.04803466796875, 0.00675201416015625, -0.037872314453125, 0.00803375244140625, -0.027496337890625, 0.06488037109375, 0.036102294921875, 0.007755279541015625, 0.0063934326171875, 0.0286102294921875, 0.01934814453125, 0.01873779296875, 0.01059722900390625, 0.054046630859375, 0.031036376953125, -0.016204833984375, 0.043975830078125, 0.05377197265625, 0.045654296875, 0.004039764404296875, 0.0126495361328125, -0.0080108642578125, 0.0215301513671875, -0.061981201171875, 0.020843505859375, -0.0018491744995117188, -0.0161590576171875, 0.00907135009765625, -0.031890869140625, 0.0171356201171875, 0.007720947265625, -0.0277862548828125, -0.04949951171875, -0.00395965576171875, -0.07489013671875, 0.0263671875, 0.048858642578125, -0.0142974853515625, 0.003387451171875, -0.006099700927734375, 0.0252227783203125, 0.0171356201171875, 0.041656494140625, -1.2695789337158203e-05, 0.0166778564453125, -0.020599365234375, -0.041961669921875, 0.0196075439453125, 0.036712646484375, 0.034423828125, -0.0144195556640625, 0.0275115966796875, 0.0196075439453125, -0.0894775390625, -0.0308990478515625, -0.06842041015625, -0.024993896484375, -0.04656982421875, -0.00969696044921875, -0.04541015625, 0.01357269287109375, -0.0213165283203125, 0.0111083984375, 0.0257720947265625, -0.005901336669921875, 0.03173828125, -0.025543212890625, 0.042510986328125, 0.0285186767578125, 0.0296630859375, -0.04742431640625, 0.01543426513671875, -0.038330078125, -0.0679931640625, -0.007297515869140625, 0.0183563232421875, -0.0035915374755859375, 0.039947509765625, 0.0142669677734375, 0.061767578125, -0.0167083740234375, 0.0223236083984375, -0.02813720703125, -0.0631103515625, 0.0009469985961914062, 0.00787353515625, 0.0098724365234375, 0.0227203369140625, -0.0006833076477050781, 0.025360107421875, -0.0186920166015625, -0.005001068115234375, 0.034637451171875, -0.05322265625, 0.04486083984375, 0.004741668701171875, 0.037628173828125, -0.0294189453125, -0.058868408203125, 0.05426025390625, -0.043609619140625, -0.0445556640625, -0.05889892578125, -0.002109527587890625, -0.0372314453125, -0.0206451416015625, -0.0009093284606933594, 0.051513671875, 0.01209259033203125, 0.07086181640625, 0.00475311279296875, -0.01317596435546875, -0.02508544921875, 0.0101470947265625, 0.0175933837890625, -0.0029277801513671875, -0.03515625, -0.0029239654541015625, -0.0228424072265625, 0.0111083984375, -0.0411376953125, -0.01090240478515625, 0.00981903076171875, 0.022003173828125, 0.068603515625, -0.0076141357421875, -0.01250457763671875, -0.011810302734375, 0.005092620849609375, -0.0216827392578125, -0.01358795166015625, -0.01727294921875, -0.03778076171875, -0.03656005859375], index=0, object='embedding')], model='nomic-ai/nomic-embed-text-v1.5', object='list', usage=Usage(prompt_tokens=15, total_tokens=15))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=\"9umTPOs14ATgAe038b6OSohQHi5JX0SrgJztIQjd3IIRSgNR\",\n",
    ")\n",
    "response = client.embeddings.create(\n",
    "  model=\"nomic-ai/nomic-embed-text-v1.5\",\n",
    "  input=\"search_document: Spiderman was a particularly entertaining movie with...\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_prompt = '''\n",
    "Generate a new profile by answering the questions. The form is a set of questions that a person (fictitious profile) answers before going to a hackathon. The profile is a complex data object. Use the examples below as inspiration for the type of answers. Each example is a concatenated string of question and answer in markdown format.\n",
    "\n",
    "The goal is to create a good representation of a participant in the hackathon in Silicon Valley, US.\n",
    "\n",
    "<form_questions>\n",
    "1. **What is your name?** \n",
    "2. **What are your interests?  (ie technical topic, coding language, business problem).**\n",
    "3. **If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.**\n",
    "4. **If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.**\n",
    "5. **What is your strongest functional role (such as developer, UX, business, product)? Please share one or two things about your experience in role your experience, for example a success, companies you worked for, how many years experience, a challenging project, etc.**\n",
    "6. **Describe your career history? Think of it like a snapshot of your LinkedIn that is relevant for your teammates at this hackathon.**\n",
    "7. **What are some of the projects you are proud of? Share links and description of what you did and why you are so proud of them**\n",
    "8. **Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?**\n",
    "</form_questions>\n",
    "\n",
    "<examples>\n",
    "1. \"## What is your name? : \\n Chloe Wong\\n\\n## What are your interests?  (ie technical topic, coding language, business problem).: \\n I'm interested in Rags and AI LLMs\\n\\n## If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.: \\n nan\\n\\n## What is your strongest functional role (such as developer, UX, business, product)? Please share one or two things about your experience in role your experience, for example a success, companies you worked for, how many years experience, a challenging project, etc.: \\n Back end developer, 10 years, build and deployed backend databases for Netflix including adding AI functionality to Netflix recommendation engines. \\n\\n## Career path from Linkedin: \\n Senior Software EngineerSenior Software Engineer, Netflix, Netflix , Jun 2018 - Present Â· 6 yrs 1 mo, PayPal 3 yrs 11 mos3 yrs 11 mos\\n\\n## Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?: \\n Product, frontend, \\n\\n## Past Projects Portfolio: \\n ### Project 1: **Netflix Recommendation Engine Enhancement**\\n\\n**Title:** AI-Powered Recommendation Engine for Netflix\\n\\n**Description:** Led the development and deployment of an advanced recommendation engine for Netflix. This project aimed to enhance the accuracy and personalization of content recommendations for users by integrating machine learning algorithms. The system utilized user behavior data, viewing history, and ratings to predict and suggest content that matched user preferences. The project included a real-time processing pipeline to ensure recommendations were updated dynamically as user interactions occurred.\\n\\n**Skills:** \\n- Python\\n- Machine Learning\\n- TensorFlow/PyTorch\\n- Apache Spark\\n- AWS (S3, EC2, Lambda)\\n- SQL\\n- Big Data (Hadoop)\\n- Data Engineering\\n- API Development\\n- Docker/Kubernetes\\n\\n### Project 2: **PayPal Fraud Detection System**\\n\\n**Title:** Real-Time Fraud Detection System for PayPal\\n\\n**Description:** Developed and deployed a robust fraud detection system for PayPal. This project involved creating a machine learning-based system to detect and prevent fraudulent transactions in real-time. The system analyzed transaction patterns, user behavior, and historical fraud data to identify suspicious activities. By implementing advanced algorithms and a scalable architecture, the system significantly reduced the incidence of fraud and enhanced the security of PayPalâ€™s platform.\\n\\n**Skills:** \\n- Java\\n- Python\\n- Machine Learning\\n- Apache Kafka\\n- NoSQL Databases (MongoDB, Cassandra)\\n- SQL\\n- Data Engineering\\n- Real-Time Processing\\n- Microservices Architecture\\n- AWS (S3, EC2, Lambda)\\n- Docker/Kubernetes\\n\\n### Project 3: **Netflix Data Lake**\\n\\n**Title:** Scalable Data Lake Infrastructure for Netflix\\n\\n**Description:** Designed and implemented a scalable data lake infrastructure for Netflix to store and manage vast amounts of data efficiently. The project involved setting up a distributed data storage system that could handle petabytes of structured and unstructured data. The data lake facilitated efficient data ingestion, storage, processing, and retrieval for various analytics and machine learning applications. This infrastructure played a crucial role in enabling data-driven decision-making across Netflix.\\n\\n**Skills:** \\n- Java\\n- Python\\n- Apache Hadoop\\n- Apache Spark\\n- AWS (S3, EMR)\\n- SQL\\n- Data Engineering\\n- ETL Processes\\n- Distributed Systems\\n- Docker/Kubernetes\"\n",
    "\n",
    "2. \"## What is your name? : \\n Rehka Mehta\\n\\n## What are your interests?  (ie technical topic, coding language, business problem).: \\n Fashion \\n\\n## If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.: \\n E-commerce\\n\\n## What is your strongest functional role (such as developer, UX, business, product)? Please share one or two things about your experience in role your experience, for example a success, companies you worked for, how many years experience, a challenging project, etc.: \\n Product manager.  I am an expert in personal recommendation.\\n\\n## Career path from Linkedin: \\n As a product manager at Wayfair, they lead the development of innovative e-commerce solutions to enhance customer experience. With expertise in data-driven decision-making, they drive projects that optimize the online shopping journey.\\n\\n## Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?: \\n Data engineer\\n\\n## Past Projects Portfolio: \\n ### Project 1: **Personalized Recommendation Engine for Wayfair**\\n\\n**Title:** Personalized Recommendation Engine for Wayfair\\n\\n**Description:** Led the development of a personalized recommendation engine for Wayfair's e-commerce platform. The project focused on leveraging customer data and advanced machine learning algorithms to provide tailored product recommendations. By analyzing user behavior, preferences, and purchase history, the engine delivered highly relevant suggestions, significantly increasing customer engagement and sales.\\n\\n**Skills:** \\n- Machine Learning\\n- Data Analysis\\n- Product Management\\n- Personalization\\n\\n### Project 2: **Enhanced Product Search and Discovery**\\n\\n**Title:** Enhanced Product Search and Discovery for Wayfair\\n\\n**Description:** Spearheaded the enhancement of Wayfair's product search and discovery features to improve the online shopping experience. The project involved optimizing search algorithms, implementing advanced filtering options, and integrating visual search capabilities. These improvements allowed customers to find products more easily and accurately, resulting in higher conversion rates and customer satisfaction.\\n\\n**Skills:** \\n- Search Engine Optimization (SEO)\\n- Data-Driven Decision Making\\n- User Experience (UX) Design\\n- Product Management\\n\\n### Project 3: **Customer Insights and Analytics Platform**\\n\\n**Title:** Customer Insights and Analytics Platform for Wayfair\\n\\n**Description:** Developed a comprehensive customer insights and analytics platform to support data-driven decision-making across Wayfair. The platform aggregated and analyzed customer data, providing actionable insights to inform marketing strategies, product development, and personalized customer experiences. This project enabled the company to better understand customer needs and preferences, driving more effective and targeted initiatives.\\n\\n**Skills:** \\n- Data Analytics\\n- Business Intelligence\\n- Product Management\\n- Customer Experience\"\n",
    "</examples>\n",
    "\n",
    "Generate a new example, like a profile, as a markdown string of question-answer pairs. Pick from a sample of product managers, engineers, managers, investors. For engineers choose from variety of profiles like startup founding engineers, data scientists, data engineer, platform engineer, frontend engineer, designer, UX etc.\n",
    "\n",
    "Consider this while creating the profile answers:\n",
    "1. Foundational Roles should be mix bag of product managers, engineers, managers, investors across various profiles\n",
    "2. For engineers, choose from a variety of profiles like startup founding engineers, data scientists, data engineers, platform engineers, frontend engineers, designers, UX, etc.\n",
    "3. For project ideas for hackathon, the idea should be small. The core fundamental of the project related to generative AI, LLMs, diffusion models or applications of AI\n",
    "4. For meeting people, it should align with other profiles of participants in the hackathon.\n",
    "5. The career should be made up of real companies that exist in the world. Use innovative famous companies from variety of sectors. Feel free to choose companies from Y combinator and a16z portfolio. Format it like Title, Company Name, Start Date - End Date.\n",
    "6. Project portfolio can have projects related classical machine learning (regression and classification), blockchain, e-commerce, recsys, search, web, mobile, ar, vr etc\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "payload = {\n",
    "  \"model\": \"accounts/fireworks/models/mixtral-8x22b-instruct\",\n",
    "  \"max_tokens\": 8192,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 40,\n",
    "  \"presence_penalty\": 0,\n",
    "  \"frequency_penalty\": 0,\n",
    "  \"temperature\": 0.6,\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": synthetic_data_prompt\n",
    "    },\n",
    "    \n",
    "  ]\n",
    "}\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\",\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {os.environ['FIREWORKS_API_KEY']}\"\n",
    "}\n",
    "# response = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kinconnect_api.config import load_dotenv\n",
    "load_dotenv()\n",
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_fireworks import ChatFireworks\n",
    "\n",
    "\n",
    "firefunc_model = \"accounts/fireworks/models/firefunction-v2\"\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str = Field(..., title=\"Question asked by the user\")\n",
    "    answer: str = Field(..., title=\"Answer given by the user\")\n",
    "    \n",
    "\n",
    "class FormSubmission(BaseModel):\n",
    "    questions: List[QuestionAnswer] = Field(..., description=\"All the questions and answers of a profile\")\n",
    "\n",
    "\n",
    "def call_api(prompt, structed_class, model):\n",
    "\n",
    "    fireworks_llm = ChatFireworks(model=model)\n",
    "    fireworks_llm = fireworks_llm.with_structured_output(structed_class)\n",
    "    \n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\n",
    "            \"output\": output.dict(),\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": e\n",
    "        }\n",
    "# extract_synthetic_qna_prompt = f'''\n",
    "# Separate the questions and answers into a structured format.\n",
    "\n",
    "# {response.json()['choices'][0]['message']['content']}\n",
    "# '''\n",
    "\n",
    "# qna_parsed = call_api(extract_synthetic_qna_prompt, FormSubmission, firefunc_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# for i in tqdm(range(0, 20)):\n",
    "#     synth_form_submission = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n",
    "#     extract_synthetic_qna_prompt = f'''\n",
    "#         Separate the questions and answers into a structured format.\n",
    "\n",
    "#         {synth_form_submission.json()['choices'][0]['message']['content']}\n",
    "#     '''\n",
    "#     qna_parsed = call_api(extract_synthetic_qna_prompt, FormSubmission, firefunc_model)\n",
    "#     synth_data.append(qna_parsed['output'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from datetime import datetime\n",
    "# pickle.dump(synth_data, open(f\"synth_data_{datetime.now().strftime('%Y%m%d%H%M%S')}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "synth_data = pickle.load(open(\"synth_data_20240701164925.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from thefuzz import process\n",
    "\n",
    "def get_form_question(question, ideal_questions):\n",
    "    best_match, score = process.extractOne(question, ideal_questions)\n",
    "    return best_match\n",
    "ideal_qna_pair={\"Timestamp\":\"01/07/2024 12:42:44\",\"What is your name? \":\"Nehil\",\"What are your interests? (ie technical topic, coding language, business problem).\":\"test\",\"If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.\":\"test\",\"What is your strongest functional role (such as developer, UX, business, product)? Please share one or two things about your experience in role your experience, for example a success, companies you worked for, how many years experience, a challenging project, etc.\":\"test\",\"Describe your career history? Think of it like a snapshot of your LinkedIn that is relevant for your teammates at this hackathon.\":\"test\",\"What are some of the projects you are proud of? Share links and description of what you did and why you are so proud of them\":\"test\",\"Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?\":\"test\",\"What your email? (we will send you matching profiles there)\":\"\",\"Email address\":\"jain.nehil@gmail.com\"}\n",
    "ideal_questions = ideal_qna_pair.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_pairs = [{get_form_question(item['question'], ideal_questions): item['answer'] for item in data['questions']} for data in synth_data if data is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_profiles = []\n",
    "\n",
    "for qna_pair in qna_pairs:\n",
    "    print(qna_pair)\n",
    "    markdown_profile = convert_question_answer_pair_to_markdown(qna_pair)\n",
    "    career_history = extract_career_history(markdown_profile)\n",
    "    profile_details = extract_profile_details(markdown_profile)\n",
    "    portfolio = extract_portfolio(markdown_profile)\n",
    "    profile = profile_details['output']\n",
    "    profile['career_history'] = career_history['output']\n",
    "    profile['portfolio'] = portfolio['output']\n",
    "    profile['form_submission'] = markdown_profile\n",
    "    print(profile)\n",
    "    processed_profiles.append(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Names(BaseModel):\n",
    "    names: List[str] = Field(..., title=\"Names of a hackathon participants in Silicon Valley. In 2024. It should have diverisity of gender, race, ethnicity in the software engineering world.\")\n",
    "resp = call_api('Give 15 full name. Have the names of people who are Indian, Chinese, Korean, Japanese, Afrian american, White software engineer common names. Only give proper names.', Names, mistral_model)\n",
    "resp2 = call_api('Give 20 full name. Have the names of people software engineer common names. Only give proper names.', Names, mistral_model)\n",
    "unique_names = list(set(resp2['output']['names'] + resp['output']['names']))\n",
    "\n",
    "for processed_profile in processed_profiles:\n",
    "    print(processed_profile)\n",
    "    if unique_names:\n",
    "        original_name   = processed_profile['name']\n",
    "        processed_profile['name'] = unique_names.pop(random.randrange(len(unique_names)))\n",
    "        processed_profile['form_submission'] = processed_profile['form_submission'].replace(original_name, processed_profile['name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_profiles_df = pd.DataFrame(processed_profiles)\n",
    "process_profiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinconnect_api.config import MONGO_CONNECTION_STRING\n",
    "from pymongo import MongoClient\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client['kinconnect']\n",
    "profiles_collection = db['profiles']\n",
    "for profile in processed_profiles:\n",
    "    profiles_collection.update_one(\n",
    "        {\"name\": profile['name']},\n",
    "        {\"$set\": profile},\n",
    "        upsert=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "fp = '/Users/nehiljain/code/kinconnect/kinconnect_api/data/processed/processed_profiles_20240702115056.pkl'\n",
    "data = pickle.load(open(fp, \"rb\"))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_sumissions = [profile['form_submission'] for profile in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parsing the specific question and its answer\n",
    "import re\n",
    "\n",
    "def get_question_answer_from_form_submission(question, form_submission):\n",
    "    \n",
    "    pattern = re.compile(rf\"{re.escape(question)}\\n(.*?)\\n##\", re.DOTALL)\n",
    "    match = pattern.search(form_submission)\n",
    "\n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "    else:\n",
    "        print(\"Question not found or no answer available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_questions = [\n",
    "    {\n",
    "        'form_submission': form_submission,\n",
    "        'people_to_meet': get_question_answer_from_form_submission(question = \"## Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?\", form_submission=form_submission),\n",
    "        'project_idea': get_question_answer_from_form_submission(question = \"## If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.\", form_submission=form_submission)\n",
    "    }\n",
    "    for form_submission in form_sumissions\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([{\"context\": f\"\"\"Topic: {intent_question['people_to_meet']['question']}\n",
    "Request: {intent_question['people_to_meet']['answer']}\n",
    "\n",
    "Topic: {intent_question['project_idea']['question']}\n",
    "Request: {intent_question['project_idea']['answer']}\"\"\"}\n",
    "for intent_question in intent_questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kinconnect_api.config import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_fireworks import ChatFireworks\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def call_api(prompt, model):\n",
    "\n",
    "    fireworks_llm = ChatFireworks(model=model)\n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\n",
    "            \"output\": output.content,\n",
    "            \"error\": None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": e\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIREFUNC_MODEL: str = \"accounts/fireworks/models/firefunction-v2\"\n",
    "MISTRAL_MODEL: str = \"accounts/fireworks/models/mistral-7b-instruct-v3\"\n",
    "LLAMA_70B_MODEL: str = 'accounts/fireworks/models/llama-v3-70b-instruct'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = \"\"\"I have a request to match with a database of engineers, designers, project managers etc. This request in the form of answers to two questions. \n",
    "\n",
    "Each profile in database includes their skills, projects, career history, and interests. \n",
    "The goal is to expand this request into one cohesive ask to ensure it captures all relevant aspects and nuances needed for accurate matching. \n",
    "\n",
    "Here is the request in question answer pairs:\n",
    "\n",
    "# Query Context\n",
    "\"{context}\"\n",
    "\n",
    "Please expand this request to include additional relevant details, such as specific skills, roles, project types, and any other contextual information that would improve the accuracy of matching with the profiles in the database. Consider what someone might need in a hackathon context, including complementary skills, leadership qualities, and relevant experience. This request will be used to do semantic search on the database. So the description and content of the request is very very crucial for accuracy.\n",
    "\n",
    "Respond in <expanded_request> xml tags. The request should have all the answers and details. No yapping. No other text.\"\"\"\n",
    "\n",
    "rewrite_summary_query = '''\n",
    "Understand the request and rewrite it in a easy to understand manner. Make sure to capture all the details. Write in 2 paragraphs like a formal and professional tone. Describe technologies, skills and details in specific details.\n",
    "\n",
    "Request: {context}\n",
    "\n",
    "The response should be just the request, no yapping.\n",
    "'''\n",
    "\n",
    "df['query_prompt'] = df['context'].apply(lambda x: query_prompt.format(context=x))\n",
    "query_string = ''\n",
    "for index, row in df.sample(frac=0.1).iterrows():\n",
    "    resp = call_api(row['query_prompt'], MISTRAL_MODEL)\n",
    "    print(row['query_prompt'])\n",
    "    print(\"-\"*100)\n",
    "    print(resp['output'])\n",
    "    print(\"-\"*100)\n",
    "    query_string = call_api(rewrite_summary_query.format(context=resp['output']), LLAMA_70B_MODEL)['output']\n",
    "    print(query_string)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinconnect_api.db import get_vector_store, PROFILES_COLLECTION\n",
    "import pandas as pd\n",
    "\n",
    "vs = get_vector_store()\n",
    "\n",
    "def get_match_profiles(query_text):\n",
    "    \n",
    "    docs = vs.similarity_search_with_score(query_text, k=5)\n",
    "    profile_names = [doc.metadata['name'] for doc, score in docs]\n",
    "    profiles = list(PROFILES_COLLECTION.find({'name': {'$in': profile_names}}))\n",
    "    return profiles\n",
    "\n",
    "profile_matches = get_match_profiles(query_string)\n",
    "df = pd.DataFrame(profile_matches)\n",
    "df.drop(columns=['_id', 'form_submission'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_explain_prompt_template = '''\n",
    "You are given a detailed, expanded query and a matched profile of an engineer. Your task is to generate a summary explanation that highlights why the profile is a good match for the query. The summary should include key points about the engineer's skills, experiences, and projects that align with the needs and goals outlined in the query. Ensure that the explanation is clear, concise, and compelling, emphasizing the most relevant aspects of the match.\n",
    "\n",
    "Expanded Query:\n",
    "\n",
    "Copy code\n",
    "{expanded_query}\n",
    "Matched Profile:\n",
    "\n",
    "Copy code\n",
    "{matched_profile}\n",
    "\n",
    "Your response should be technical, consise and fun to read. It should be no more than 100 words. No yapping.\n",
    "Enclose your response in <summary> tags.\n",
    "'''\n",
    "summary_explain_prompt = summary_explain_prompt_template.format(expanded_query=query_string, matched_profile=profile_matches[3]['form_submission'])\n",
    "\n",
    "resp = call_api(summary_explain_prompt, LLAMA_70B_MODEL)\n",
    "resp['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = '/Users/nehiljain/code/kinconnect/kinconnect_api/data/processed/matches_David_Johnson__Fake_Profile__20240702_170146_parquet'\n",
    "df = pd.read_parquet(fp)\n",
    "print(df.iloc[0]['portfolio'])\n",
    "print('-'*100)\n",
    "print(df.iloc[0]['summary_explanation'])\n",
    "print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 13:03:24,128 - DEBUG - {\"message\": \"Server selection started\", \"selector\": \"<function writable_server_selector at 0x12013ff60>\", \"operation\": \"delete\", \"topologyDescription\": \"<TopologyDescription id: 6687000c97c4f2f1c260e798, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-n01rlqs-shard-00-00.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-n01rlqs-shard-00-01.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}}\n",
      "2024-07-04 13:03:24,130 - DEBUG - {\"message\": \"Waiting for suitable server to become available\", \"selector\": \"<function writable_server_selector at 0x12013ff60>\", \"operation\": \"delete\", \"topologyDescription\": \"<TopologyDescription id: 6687000c97c4f2f1c260e798, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-n01rlqs-shard-00-00.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-n01rlqs-shard-00-01.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"remainingTimeMS\": 29}\n",
      "2024-07-04 13:03:24,380 - DEBUG - {\"message\": \"Server selection succeeded\", \"selector\": \"<function writable_server_selector at 0x12013ff60>\", \"operation\": \"delete\", \"topologyDescription\": \"<TopologyDescription id: 6687000c97c4f2f1c260e798, topology_type: ReplicaSetWithPrimary, servers: [<ServerDescription ('ac-n01rlqs-shard-00-00.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.08027916599530727>, <ServerDescription ('ac-n01rlqs-shard-00-01.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.07341750001069158>, <ServerDescription ('ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net', 27017) server_type: RSPrimary, rtt: 0.07401337509509176>]>\", \"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:24,841 - DEBUG - {\"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"message\": \"Command started\", \"command\": \"{\\\"delete\\\": \\\"profiles\\\", \\\"ordered\\\": true, \\\"lsid\\\": {\\\"id\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"AZzS9fI5TLG+tl7plSaMBg==\\\", \\\"subType\\\": \\\"04\\\"}}}, \\\"$clusterTime\\\": {\\\"clusterTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 7}}, \\\"signature\\\": {\\\"hash\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"/o4/dD06BZHXSgnbNt60Xv+cS8s=\\\", \\\"subType\\\": \\\"00\\\"}}, \\\"keyId\\\": 7348153241990856724}}, \\\"writeConcern\\\": {\\\"w\\\": \\\"majority\\\"}, \\\"$db\\\": \\\"kinconnect\\\", \\\"deletes\\\": [{\\\"q\\\": {\\\"name\\\": \\\"Nehil Jain (TEST)\\\"}}]}\", \"commandName\": \"delete\", \"databaseName\": \"kinconnect\", \"requestId\": 1358580979, \"operationId\": 1358580979, \"driverConnectionId\": 1, \"serverConnectionId\": 165053, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:24,926 - DEBUG - {\"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"message\": \"Command succeeded\", \"durationMS\": 85.66600000000001, \"reply\": \"{\\\"n\\\": 1, \\\"electionId\\\": {\\\"$oid\\\": \\\"7fffffff0000000000000108\\\"}, \\\"opTime\\\": {\\\"ts\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 15}}, \\\"t\\\": 264}, \\\"ok\\\": 1.0, \\\"$clusterTime\\\": {\\\"clusterTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 16}}, \\\"signature\\\": {\\\"hash\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"/o4/dD06BZHXSgnbNt60Xv+cS8s=\\\", \\\"subType\\\": \\\"00\\\"}}, \\\"keyId\\\": 7348153241990856724}}, \\\"operationTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 15}}}\", \"commandName\": \"delete\", \"databaseName\": \"kinconnect\", \"requestId\": 1358580979, \"operationId\": 1358580979, \"driverConnectionId\": 1, \"serverConnectionId\": 165053, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:24,928 - INFO - Deleted profile with name: Nehil Jain (TEST)\n",
      "2024-07-04 13:03:24,929 - DEBUG - {\"message\": \"Server selection started\", \"selector\": \"<function writable_server_selector at 0x12013ff60>\", \"operation\": \"delete\", \"topologyDescription\": \"<TopologyDescription id: 6687000c97c4f2f1c260e798, topology_type: ReplicaSetWithPrimary, servers: [<ServerDescription ('ac-n01rlqs-shard-00-00.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.08027916599530727>, <ServerDescription ('ac-n01rlqs-shard-00-01.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.07341750001069158>, <ServerDescription ('ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net', 27017) server_type: RSPrimary, rtt: 0.07401337509509176>]>\", \"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}}\n",
      "2024-07-04 13:03:24,930 - DEBUG - {\"message\": \"Server selection succeeded\", \"selector\": \"<function writable_server_selector at 0x12013ff60>\", \"operation\": \"delete\", \"topologyDescription\": \"<TopologyDescription id: 6687000c97c4f2f1c260e798, topology_type: ReplicaSetWithPrimary, servers: [<ServerDescription ('ac-n01rlqs-shard-00-00.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.08027916599530727>, <ServerDescription ('ac-n01rlqs-shard-00-01.5e8k2is.mongodb.net', 27017) server_type: RSSecondary, rtt: 0.07341750001069158>, <ServerDescription ('ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net', 27017) server_type: RSPrimary, rtt: 0.07401337509509176>]>\", \"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:24,931 - DEBUG - {\"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"message\": \"Command started\", \"command\": \"{\\\"delete\\\": \\\"profile_chunks\\\", \\\"ordered\\\": true, \\\"lsid\\\": {\\\"id\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"AZzS9fI5TLG+tl7plSaMBg==\\\", \\\"subType\\\": \\\"04\\\"}}}, \\\"$clusterTime\\\": {\\\"clusterTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 16}}, \\\"signature\\\": {\\\"hash\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"/o4/dD06BZHXSgnbNt60Xv+cS8s=\\\", \\\"subType\\\": \\\"00\\\"}}, \\\"keyId\\\": 7348153241990856724}}, \\\"writeConcern\\\": {\\\"w\\\": \\\"majority\\\"}, \\\"$db\\\": \\\"kinconnect\\\", \\\"deletes\\\": [{\\\"q\\\": {\\\"name\\\": \\\"Nehil Jain (TEST)\\\"}}]}\", \"commandName\": \"delete\", \"databaseName\": \"kinconnect\", \"requestId\": 1624379149, \"operationId\": 1624379149, \"driverConnectionId\": 1, \"serverConnectionId\": 165053, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:25,072 - DEBUG - {\"clientId\": {\"$oid\": \"6687000c97c4f2f1c260e798\"}, \"message\": \"Command succeeded\", \"durationMS\": 141.13400000000001, \"reply\": \"{\\\"n\\\": 9, \\\"electionId\\\": {\\\"$oid\\\": \\\"7fffffff0000000000000108\\\"}, \\\"opTime\\\": {\\\"ts\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 21}}, \\\"t\\\": 264}, \\\"ok\\\": 1.0, \\\"$clusterTime\\\": {\\\"clusterTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 29}}, \\\"signature\\\": {\\\"hash\\\": {\\\"$binary\\\": {\\\"base64\\\": \\\"/o4/dD06BZHXSgnbNt60Xv+cS8s=\\\", \\\"subType\\\": \\\"00\\\"}}, \\\"keyId\\\": 7348153241990856724}}, \\\"operationTime\\\": {\\\"$timestamp\\\": {\\\"t\\\": 1720123404, \\\"i\\\": 21}}}\", \"commandName\": \"delete\", \"databaseName\": \"kinconnect\", \"requestId\": 1624379149, \"operationId\": 1624379149, \"driverConnectionId\": 1, \"serverConnectionId\": 165053, \"serverHost\": \"ac-n01rlqs-shard-00-02.5e8k2is.mongodb.net\", \"serverPort\": 27017}\n",
      "2024-07-04 13:03:25,073 - INFO - Deleted chunks associated with profile name: Nehil Jain (TEST)\n"
     ]
    }
   ],
   "source": [
    "from kinconnect_api.db import delete_profile_and_chunks\n",
    "# Example usage\n",
    "profile_name_to_delete = \"Nehil Jain (TEST)\"\n",
    "delete_profile_and_chunks(profile_name_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional, List\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pymongo import MongoClient\n",
    "from typing import List, Dict\n",
    "from langchain_fireworks import FireworksEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "\n",
    "\n",
    "def get_vector_store() -> MongoDBAtlasVectorSearch:\n",
    "    return MongoDBAtlasVectorSearch.from_connection_string(\n",
    "        connection_string = os.getenv('MONGO_CONNECTION_STRING'),\n",
    "        namespace = \"kinconnect.profile_chunks\",\n",
    "        embedding = FireworksEmbeddings(model=\"nomic-ai/nomic-embed-text-v1.5\"),\n",
    "        index_name = \"profile_chunks\"\n",
    "    )\n",
    "\n",
    "def get_profile_by_name(name: str) -> Dict:\n",
    "    client = MongoClient(os.getenv('MONGO_CONNECTION_STRING'))\n",
    "    DB = client['kinconnect']\n",
    "    PROFILES_COLLECTION = DB['profiles']\n",
    "    return PROFILES_COLLECTION.find_one({'name': name})\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "FIREWORKS_API_KEY: str = os.getenv('FIREWORKS_API_KEY')\n",
    "FIREFUNC_MODEL: str = \"accounts/fireworks/models/firefunction-v2\"\n",
    "MISTRAL_MODEL: str = \"accounts/fireworks/models/mistral-7b-instruct-v3\"\n",
    "LLAMA_70B_MODEL: str = 'accounts/fireworks/models/llama-v3-70b-instruct'\n",
    "\n",
    "def call_fireworks_api_no_structure(prompt: str, model: str) -> Dict[str, Optional[Any]]:\n",
    "    \"\"\"\n",
    "    Calls the API with the given prompt and model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the API.\n",
    "        model (str): The model to use for the API call.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Optional[Any]]: The output from the API call or an error message.\n",
    "    \"\"\"\n",
    "    fireworks_llm = ChatFireworks(model=model)\n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\n",
    "            \"output\": output.content,\n",
    "            \"error\": None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed: {e}\")\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": e\n",
    "        }\n",
    "\n",
    "\n",
    "def call_fireworks_api_with_structure(prompt: str, structured_class: Any, model: str) -> Dict[str, Any]:\n",
    "    \"\"\"Calls the Fireworks API with a structured output.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the API.\n",
    "        structured_class (Any): The structured class to use for the output.\n",
    "        model (str): The model to use for the API call.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The output from the API call.\n",
    "    \"\"\"\n",
    "    fireworks_llm = ChatFireworks(model=model).with_structured_output(structured_class)\n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\"output\": output.dict(), \"error\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling API: {e}\")\n",
    "        return {\"output\": None, \"error\": e}\n",
    "\n",
    "QUERY_PROMPT: str = \"\"\"I have a request to match with a database of engineers, designers, project managers etc. This request in the form of answers to two questions. \n",
    "\n",
    "Each profile in database includes their skills, projects, career history, and interests. \n",
    "The goal is to expand this request into one cohesive ask to ensure it captures all relevant aspects and nuances needed for accurate matching. \n",
    "\n",
    "Here is the request in question answer pairs:\n",
    "\n",
    "# Query Context\n",
    "\"{context}\"\n",
    "\n",
    "Please expand this request to include additional relevant details, such as specific skills, roles, project types, and any other contextual information that would improve the accuracy of matching with the profiles in the database. Consider what someone might need in a hackathon context, including complementary skills, leadership qualities, and relevant experience. This request will be used to do semantic search on the database. So the description and content of the request is very very crucial for accuracy.\n",
    "\n",
    "Respond in <expanded_request> xml tags. The request should have all the answers and details. No yapping. No other text.\"\"\"\n",
    "\n",
    "REWRITE_SUMMARY_QUERY: str = '''\n",
    "Understand the request and rewrite it in a easy to understand manner. Make sure to capture all the details. Write in 2 paragraphs like a formal and professional tone. Describe technologies, skills and details in specific details.\n",
    "\n",
    "Request: {context}\n",
    "'''\n",
    "\n",
    "\n",
    "def extract_answer_from_submission(question: str, form_submission: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extracts the answer to a specific question from the form submission.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to search for in the form submission.\n",
    "        form_submission (str): The form submission text.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict[str, str]]: A dictionary containing the question and its answer, or None if not found.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(rf\"{re.escape(question)}\\n(.*?)\\n##\", re.DOTALL)\n",
    "    match = pattern.search(form_submission)\n",
    "\n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_profile_matching_request(profile: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Creates a profile matching request based on the given profile.\n",
    "\n",
    "    Args:\n",
    "        profile (Dict[str, Any]): The profile containing form submission data.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The expanded query string or None if an error occurred.\n",
    "    \"\"\"\n",
    "    form_submission: str = profile['form_submission']\n",
    "    people_to_meet: Optional[Dict[str, str]] = extract_answer_from_submission(\n",
    "        question=\"## Are you interested in meeting people with a specific skill set (either one that you lack or one that you already have but want to clone yourself to speed up building). What is the skills sets that you are looking to meet?\",\n",
    "        form_submission=form_submission\n",
    "    )\n",
    "    project_idea: Optional[Dict[str, str]] = extract_answer_from_submission(\n",
    "        question=\"## If you have a project idea, describe your idea . Please include whether what sector it is in, and what business problem it is solving and for whom. If you donâ€™t have a project, skip this question.\",\n",
    "        form_submission=form_submission\n",
    "    )\n",
    "\n",
    "    if not people_to_meet or not project_idea:\n",
    "        print(\"Failed to extract necessary information from form submission.\")\n",
    "        return None\n",
    "\n",
    "    context: str = f\"\"\"Topic: {people_to_meet['question']}\n",
    "        Request: {people_to_meet['answer']}\n",
    "\n",
    "        Topic: {project_idea['question']}\n",
    "        Request: {project_idea['answer']}\"\"\"\n",
    "    \n",
    "    expanded_request: Optional[str] = generate_expanded_request(context)\n",
    "    if expanded_request is None:\n",
    "        return None\n",
    "\n",
    "    expanded_query_string: Optional[str] = summarize_expanded_request(expanded_request)\n",
    "    return expanded_query_string\n",
    "\n",
    "def generate_expanded_request(context: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generates an expanded request using the given context.\n",
    "\n",
    "    Args:\n",
    "        context (str): The context to use for generating the expanded request.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The expanded request or None if an error occurred.\n",
    "    \"\"\"\n",
    "    rewrite_query_prompt: str = QUERY_PROMPT.format(context=context)\n",
    "    response: Dict[str, Optional[Any]] = call_fireworks_api_no_structure(rewrite_query_prompt, MISTRAL_MODEL)\n",
    "    if response['error']:\n",
    "        print(\"Failed to generate expanded request.\")\n",
    "        return None\n",
    "    return response['output']\n",
    "\n",
    "def summarize_expanded_request(expanded_request: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Summarizes the expanded request.\n",
    "\n",
    "    Args:\n",
    "        expanded_request (str): The expanded request to summarize.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The summarized expanded request or None if an error occurred.\n",
    "    \"\"\"\n",
    "    summary_prompt: str = REWRITE_SUMMARY_QUERY.format(context=expanded_request)\n",
    "    response: Dict[str, Optional[Any]] = call_fireworks_api_no_structure(summary_prompt, LLAMA_70B_MODEL)\n",
    "    if response['error']:\n",
    "        return None\n",
    "    return response['output']\n",
    "\n",
    "\n",
    "def get_match_summary_explanation(expanded_request: str, profile: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get the summary explanation for a match.\n",
    "    \"\"\"\n",
    "    summary_explain_prompt_template = '''\n",
    "    You are given a detailed, expanded query and a matched profile of an engineer. Your task is to generate a summary explanation that highlights why the profile is a good match for the query. The summary should include key points about the engineer's skills, experiences, and projects that align with the needs and goals outlined in the query. Ensure that the explanation is clear, concise, and compelling, emphasizing the most relevant aspects of the match.\n",
    "\n",
    "    Expanded Query:\n",
    "\n",
    "    Copy code\n",
    "    {expanded_query}\n",
    "    Matched Profile:\n",
    "\n",
    "    Copy code\n",
    "    {matched_profile}\n",
    "\n",
    "    Your response should be technical, consise and fun to read. It should be no more than 100 words. No yapping.\n",
    "    Enclose your response in <summary> tags.\n",
    "    '''\n",
    "    summary_explain_prompt = summary_explain_prompt_template.format(expanded_query=expanded_request, matched_profile=profile['form_submission'])\n",
    "    response: Dict[str, Optional[Any]] = call_fireworks_api_no_structure(summary_explain_prompt, LLAMA_70B_MODEL)\n",
    "    class SummaryExplanation(BaseModel):\n",
    "        summary: str = Field(description=\"The summary explanation for a matched profile to the request.\")\n",
    "    structure_parse_prompt = f'''\n",
    "    You are given a response from an LLM. Your task is to parse the response and return the summary explanation.\n",
    "    Response:\n",
    "    {response}\n",
    "    '''\n",
    "    summary_response = call_fireworks_api_with_structure(structure_parse_prompt, SummaryExplanation, FIREFUNC_MODEL)\n",
    "    return summary_response['output']['summary']\n",
    "\n",
    "def get_match_profiles(query_text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Retrieves matching profiles based on the query text.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The query text to search for matching profiles.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of matching profiles.\n",
    "    \"\"\"\n",
    "    vector_store = get_vector_store()\n",
    "    documents_with_scores = vector_store.similarity_search_with_score(query_text, k=5)\n",
    "    profile_names = [doc.metadata['name'] for doc, score in documents_with_scores]\n",
    "    profiles = list(PROFILES_COLLECTION.find({'name': {'$in': profile_names}}))\n",
    "    return profiles\n",
    "\n",
    "def get_matches_for_profile_with_name(name: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retrieves matching profiles for a given profile name.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the profile to find matches for.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: A DataFrame containing the matching profiles or None if no matches found.\n",
    "    \"\"\"\n",
    "    profile = get_profile_by_name(name)\n",
    "    if not profile:\n",
    "        print(f\"No profile found with name: {name}\")\n",
    "        return None\n",
    "    query_string = create_profile_matching_request(profile)\n",
    "    if not query_string:\n",
    "        print(\"Failed to create profile matching request.\")\n",
    "        return None\n",
    "    profile_matches = get_match_profiles(query_string)\n",
    "    profile_matches = [match for match in profile_matches if match.get('name') != name]\n",
    "    df = pd.DataFrame(profile_matches)\n",
    "    df['summary_explanation'] = df.apply(lambda row: get_match_summary_explanation(expanded_request=query_string, profile=row), axis=1)\n",
    "    df.drop(columns=['_id', 'form_submission'], inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def handler(pd: \"pipedream\"):\n",
    "    # Reference data from previous steps\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(os.getenv('MONGO_CONNECTION_STRING'))\n",
    "    DB = client['kinconnect']\n",
    "    PROFILES_COLLECTION = DB['profiles']\n",
    "    PROFILE_CHUNKS_COLLECTION = DB['profile_chunks']\n",
    "    profile_name = pd.steps[\"save_to_db\"][\"$return_value\"][\"inserted_profile\"][\"name\"]\n",
    "    print(profile_name)\n",
    "    # matches_df = get_matches_for_profile_with_name(\"Nehil\")\n",
    "    # Return data for use in future steps\n",
    "    # return matches_df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_fireworks import ChatFireworks, FireworksEmbeddings\n",
    "\n",
    "portfolio_prompt_string='''\n",
    "You are a data generation app which extracts the relevant details about a engineering/design/product management profile. \n",
    "We have a form submission about the profile of the participant. They have answered few questions about themselves.\n",
    "Find all the relevant details about their portfolio from their answers. Make sure to look at the details of each project. You want to collect a list of projects they have worked on.\n",
    "                        \n",
    "# BIO\n",
    "{bio}\n",
    "'''\n",
    "\n",
    "profile_prompt_string='''You are a data generation app which extracts the relevant details about a engineering/design/product management profile. \n",
    "We have a form submission about the profile of the participant. They have answered few questions about themselves.\n",
    "Given their form submission which asks them a few questions. Find all the attributes about the profile so you can call the right function.\n",
    "Find all the relevant details about their profile. Find their skills, accolades, honors and current interests.\n",
    "                  \n",
    "# BIO\n",
    "{bio}\n",
    "'''\n",
    "\n",
    "career_history_prompt_string='''\n",
    "Use the questions answered by participants of a hackathon to call the function with the right arguments.\n",
    "Find the relevant career related information in the bio to create career history. Make sure you capture all the companies and dates in order.\n",
    "This information is very important so missing any career event will be expensive mistake.\n",
    "\n",
    "If date is not mentioned or it says present/current, then the end date should be current date which is in timestamp.\n",
    "\n",
    "# BIO\n",
    "{bio}\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class ProfileModel(BaseModel):\n",
    "    name: str = Field(..., title=\"Name of the person\")\n",
    "    honors: list[str] = Field(None, title=\"Honors, Awards and recognition they have received in life\")\n",
    "    interests: list[str] = Field(..., title=\"Interests and current focus of theirs the work or the event\")\n",
    "    skills: list[str] = Field(..., title=\"Skills they have\")\n",
    "\n",
    "\n",
    "class CareerEntry(BaseModel):\n",
    "    company: str = Field(..., description=\"Company they worked at\")\n",
    "    title: str = Field(..., description=\"Title of the role they held\")\n",
    "    description: str = Field(..., description=\"Description of the role they held\")\n",
    "    start_date: str = Field(..., description=\"Start date of the role\")\n",
    "    end_date: str = Field(..., description=\"End date of the role\")\n",
    "\n",
    "class CareerHistory(BaseModel):\n",
    "    history: List[CareerEntry] = Field(..., description=\"All the companies you have been at as part of your career\")\n",
    "\n",
    "\n",
    "class ProjectEntry(BaseModel):\n",
    "    title: str = Field(..., title=\"Title of the project\")\n",
    "    description: str = Field(..., title=\"Description of the project\")\n",
    "\n",
    "class Portfolio(BaseModel):\n",
    "    projects: List[ProjectEntry] = Field(..., description=\"All the projects you have worked on\")\n",
    "\n",
    "def call_api(prompt, structed_class, model):\n",
    "\n",
    "    fireworks_llm = ChatFireworks(model=model)\n",
    "    fireworks_llm = fireworks_llm.with_structured_output(structed_class)\n",
    "    \n",
    "    try:\n",
    "        output = fireworks_llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\n",
    "            \"output\": output.dict(),\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": e\n",
    "        }\n",
    "\n",
    "def convert_question_answer_pair_to_markdown(question_answer_pair):\n",
    "    markdown = \"\"\n",
    "    for question, answer in question_answer_pair.items():\n",
    "        markdown += f\"## {question}\\n{answer}\\n\\n\"\n",
    "    return markdown\n",
    "\n",
    "def extract_career_history(question_answer_pair_markdown):\n",
    "    career_history_prompt = career_history_prompt_string.format(bio=question_answer_pair_markdown)\n",
    "    firefunc_model = \"accounts/fireworks/models/firefunction-v2\"\n",
    "    return call_api(career_history_prompt, CareerHistory, firefunc_model)\n",
    "\n",
    "\n",
    "def extract_profile_details(question_answer_pair_markdown):\n",
    "    profile_prompt = profile_prompt_string.format(bio=question_answer_pair_markdown)\n",
    "    mistral_model = \"accounts/fireworks/models/mistral-7b-instruct-v3\"\n",
    "    return call_api(profile_prompt, ProfileModel, mistral_model)\n",
    "\n",
    "def extract_portfolio(question_answer_pair_markdown):\n",
    "    portfolio_prompt = portfolio_prompt_string.format(bio=question_answer_pair_markdown)\n",
    "    mistral_model = \"accounts/fireworks/models/mistral-7b-instruct-v3\"\n",
    "    return call_api(portfolio_prompt, Portfolio, mistral_model)\n",
    "\n",
    "\n",
    "def handler(pd: \"pipedream\"):\n",
    "    embedding_model = FireworksEmbeddings(model=\"nomic-ai/nomic-embed-text-v1.5\")\n",
    "    question_answer_pair = pd.steps[\"get_formated_question_answer_pairs\"][\"$return_value\"]\n",
    "    markdown_profile = convert_question_answer_pair_to_markdown(question_answer_pair)\n",
    "    career_history = extract_career_history(markdown_profile)\n",
    "    profile_details = extract_profile_details(markdown_profile)\n",
    "    portfolio = extract_portfolio(markdown_profile)\n",
    "    profile = profile_details['output']\n",
    "    profile['career_history'] = career_history['output']\n",
    "    profile['portfolio'] = portfolio['output']\n",
    "    profile['form_submission'] = markdown_profile\n",
    "    print(profile)\n",
    "    profile['embeddings'] = embedding_model.embed_query(markdown_profile)\n",
    "    return profile\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Benjamin Lee (Fake Profile)', 'career_history': {'history': array([{'company': 'Airbnb', 'description': 'Built and optimized frontend applications for Airbnb, focusing on enhancing user experience and improving performance.', 'end_date': '2018', 'start_date': '2016', 'title': 'Frontend Developer'},\n",
      "       {'company': 'Stripe', 'description': \"Worked on developing and maintaining Stripe's frontend applications, ensuring a seamless and user-friendly experience for customers.\", 'end_date': '2024-07-05 19:42:38', 'start_date': '2018', 'title': 'Senior Frontend Developer'}],\n",
      "      dtype=object)}, 'portfolio': {'projects': array([{'description': 'Developed a frontend application for an e-commerce platform that provided personalized product recommendations based on user preferences and browsing history. The application improved the user experience and increased customer engagement, leading to a significant increase in sales.', 'title': 'Personalized Product Recommendations for E-commerce Platform'},\n",
      "       {'description': 'Built an interactive frontend application for a real estate platform, allowing users to search for properties, view detailed listings, and book appointments with agents. The application improved the user experience and made it easier for customers to find their desired properties.', 'title': 'Interactive Frontend Application for Real Estate Platform'},\n",
      "       {'description': 'Developed a mobile-first web application for a fitness platform, enabling users to access workout plans, track their progress, and connect with personal trainers. The application improved the user experience and helped the platform attract more customers.', 'title': 'Mobile-first Web Application for Fitness Platform'}],\n",
      "      dtype=object)}}, {'name': 'Noah Park (Fake Profile)', 'career_history': {'history': array([{'company': 'Airbnb', 'description': \"Built the frontend for Airbnb's Experiences feature, which significantly improved user engagement and increased bookings.\", 'end_date': '2024-07-05 19:42:45', 'start_date': '2018', 'title': 'Frontend Engineer'},\n",
      "       {'company': 'Dropbox', 'description': \"Developed the frontend for Dropbox's file sharing and collaboration features, which enabled users to easily share files with others and collaborate on projects in real-time.\", 'end_date': '2018', 'start_date': '2016', 'title': 'Frontend Engineer'}],\n",
      "      dtype=object)}, 'portfolio': {'projects': array([{'description': \"Built the frontend for Airbnb's Experiences feature, which allowed users to book unique and immersive activities in their travel destinations. The project involved creating a user-friendly interface that showcased available experiences, provided detailed information about each activity, and facilitated the booking process. Skills: React.js, JavaScript, CSS, HTML, User Interface Design, Responsive Web Design.\", 'title': 'Airbnb Experiences Feature'},\n",
      "       {'description': \"Developed the frontend for Dropbox's file sharing and collaboration features, which enabled users to easily share files with others and collaborate on projects in real-time. The project involved creating a seamless user experience that allowed for quick file uploads, sharing, and editing. Skills: React.js, JavaScript, CSS, HTML, User Interface Design, Real-time Collaboration.\", 'title': 'Dropbox File Sharing and Collaboration'},\n",
      "       {'description': 'Built the frontend for an e-commerce personalization engine that utilized machine learning algorithms to deliver personalized product recommendations to users. The project involved creating a visually appealing and intuitive interface that displayed relevant products and allowed users to easily navigate and discover new items. Skills: React.js, JavaScript, CSS, HTML, User Interface Design, Personalization Algorithms, Machine Learning, E-commerce.', 'title': 'E-commerce Personalization Engine'}],\n",
      "      dtype=object)}}, {'name': 'Emily Nguyen (Fake Profile)', 'career_history': {'history': array([{'company': 'Fintech Company', 'description': '', 'end_date': 'Jun 2017', 'start_date': 'Jun 2015', 'title': 'Junior Frontend Engineer'},\n",
      "       {'company': 'E-commerce Platform', 'description': '', 'end_date': 'Nov 2019', 'start_date': 'Jul 2017', 'title': 'Frontend Engineer'},\n",
      "       {'company': 'Y Combinator-backed Startup', 'description': '', 'end_date': '2024-07-05 19:42:52', 'start_date': 'Dec 2019', 'title': 'Senior Frontend Engineer'}],\n",
      "      dtype=object)}, 'portfolio': {'projects': array([{'description': 'Developed a responsive web application using React.js and JavaScript for a fintech company. The application provided users with an intuitive interface to manage their financial transactions, budgeting, and investment portfolios. This project required a deep understanding of frontend development, UX design, and fintech domain knowledge.', 'title': 'Responsive Web Application for Fintech Company'},\n",
      "       {'description': 'Created a user-friendly frontend for a blockchain-based platform using React.js and JavaScript. The frontend application allowed users to interact with the platform, manage their digital assets, and perform various transactions securely. This project required expertise in frontend development, blockchain technology, and security best practices.', 'title': 'User-friendly Frontend for Blockchain-Based Platform'},\n",
      "       {'description': 'Developed a frontend application using React.js and JavaScript for an e-commerce platform. The application integrated with a machine learning-based recommendation engine to provide personalized product suggestions to users. This project required a strong understanding of frontend development, machine learning, and e-commerce domain knowledge.', 'title': 'E-commerce Product Recommendations'}],\n",
      "      dtype=object)}}, {'name': 'Amelia Patel (Fake Profile)', 'career_history': {'history': array([{'company': 'Airbnb', 'description': 'Developed a real-time chat feature for Airbnb', 'end_date': 'Dec 2021', 'start_date': 'Jun 2018', 'title': 'Frontend Engineer'},\n",
      "       {'company': 'Dropbox', 'description': \"Optimized the file-sharing feature on Dropbox's web platform\", 'end_date': 'May 2018', 'start_date': 'Jan 2016', 'title': 'Frontend Engineer'}],\n",
      "      dtype=object)}, 'portfolio': {'projects': array([{'description': \"Developed a personalized recommendation system for an e-commerce website using classical machine learning algorithms. The system analyzed user behavior and purchase history to suggest products that matched the user's preferences. The project resulted in a significant increase in sales conversion rates and improved user engagement.\", 'title': 'Personalized Recommendations for E-commerce'},\n",
      "       {'description': \"Contributed to the development of a real-time chat feature for Airbnb's web platform. The feature enabled users to communicate in real-time with their hosts and guests, improving the overall user experience and increasing user satisfaction.\", 'title': 'Real-time Chat Feature for Airbnb'},\n",
      "       {'description': \"Optimized the file-sharing feature on Dropbox's web platform, resulting in faster upload and download speeds. The project involved implementing a more efficient file-sharing algorithm and optimizing the frontend code to improve performance.\", 'title': 'File-sharing Optimization for Dropbox'},\n",
      "       {'description': 'Developed a blockchain-based supply chain management system for a major retailer. The system improved the transparency and security of the supply chain, reducing the risk of fraud and errors.', 'title': 'Blockchain-based Supply Chain Management'},\n",
      "       {'description': 'Developed an AR mobile app that enabled users to visualize furniture in their homes before purchasing. The project involved integrating AR technology into a mobile app and optimizing the user experience for a seamless shopping experience.', 'title': 'Augmented Reality (AR) Mobile App'}],\n",
      "      dtype=object)}}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# fp = '/Users/nehiljain/code/kinconnect/kinconnect_api/data/processed/matches_Nehil_Jain__TEST__20240703_160619.parquet'\n",
    "fp = '/Users/nehiljain/code/kinconnect/kinconnect_api/data/processed/processed_profiles_20240705124308.parquet'\n",
    "df = pd.read_parquet(fp)\n",
    "\n",
    "print(pd.read_parquet(fp)[['name', 'career_history', 'portfolio']].to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 12:53:43,944 - INFO - Deleted profile with name: Nehil Jain\n",
      "2024-07-05 12:53:43,981 - INFO - Deleted chunks associated with profile name: Nehil Jain\n",
      "2024-07-05 12:53:44,509 - INFO - Deleted profile with name: Nehil Jain (Test)\n",
      "2024-07-05 12:53:44,551 - INFO - Deleted chunks associated with profile name: Nehil Jain (Test)\n",
      "2024-07-05 12:53:45,171 - INFO - Deleted profile with name: Nehil Jain (Test for recording)\n",
      "2024-07-05 12:53:45,209 - INFO - Deleted chunks associated with profile name: Nehil Jain (Test for recording)\n",
      "2024-07-05 12:53:45,785 - INFO - Deleted profile with name: Nehil Jain (test for recording)\n",
      "2024-07-05 12:53:45,826 - INFO - Deleted chunks associated with profile name: Nehil Jain (test for recording)\n"
     ]
    }
   ],
   "source": [
    "from kinconnect_api.db import delete_profile_and_chunks\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "# Example usage\n",
    "profile_name_to_delete = \"Nehil Jain\"\n",
    "delete_profile_and_chunks(profile_name_to_delete)\n",
    "profile_name_to_delete = \"Nehil Jain (Test)\"\n",
    "delete_profile_and_chunks(profile_name_to_delete)\n",
    "profile_name_to_delete = \"Nehil Jain (Test for recording)\"\n",
    "delete_profile_and_chunks(profile_name_to_delete)\n",
    "profile_name_to_delete = \"Nehil Jain (test for recording)\"\n",
    "delete_profile_and_chunks(profile_name_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
